# 爬虫

- 信息收集分析整合的自动化

### 环境

- python
- pip

### HTTP协议

#### 流程

```
1. 浏览器向 DNS 服务器请求解析该 URL 中的域名所对应的 IP 地址;`
2. 解析出 IP 地址后，根据该 IP 地址和默认端口 80，和服务器建立TCP连接;`
3. 浏览器发出读取文件(URL 中域名后面部分对应的文件)的HTTP 请求，该请求报文作为 TCP 三次握手的第三个报文的数据发送给服务器;`
4. 服务器对浏览器请求作出响应，并把对应的 html 文本发送给浏览器;`
5. 浏览器将该 html 文本并显示内容;
```

![image-20240906092812292](C:\Users\泰来\AppData\Roaming\Typora\typora-user-images\image-20240906092812292.png)

### 流程

#### 模拟发送HTTP请求

- 创建Response对象

使用的对象是：<class 'requests.models.Response'>

```python
import requests

url='https://www.baidu.com/'
r=requests.get(url)
```

- 如果我们要获取网站返回的数据，可以使用 text 或者 content 属性来获取
  - text：是以字符串的形式返回数据
  - content：是以二进制的方式返回数据

##### Requests库方法

![](C:\Users\泰来\AppData\Roaming\Typora\typora-user-images\image-20240907131119973.png)

![image-20240907131204455](C:\Users\泰来\AppData\Roaming\Typora\typora-user-images\image-20240907131204455.png)

#### Header增强

有的网站会拒绝没有携带header的请求，需要给报文添加header的相关信息，包括：

- cookie
- UA
- host
- user-agent

在网页报文中收集自己的用户信息

![image-20240906095213042](C:\Users\泰来\AppData\Roaming\Typora\typora-user-images\image-20240906095213042.png)

#### 定位目标信息

<img src="C:\Users\泰来\AppData\Roaming\Typora\typora-user-images\image-20240907131540122.png" alt="image-20240907131540122" style="zoom: 80%;" />



- 使用**BeautifulSoup**库进行数据解析

```python
from bs4 import BeautifulSoup

#创建对象
soup=BeautifulSoup(
    html_doc,		#html文档字符串
    'html.parser',	#html解析器
    from_encoding='utf8'	#html文档编码
	)
```

- 常用解析器：html.parser,lxml,xml,html5lib

之后调用BeautifulSoup库提供的方法可以得到

- 标签名
  - soup.标签名
- 标签属性
  - soup.标签.name
  - soup.标签.attrs（获取全部属性）
  - soup.标签.attrs[属性名]（获取指定属性）
  - soup.标签[属性名]（获取指定属性）
  - soup.标签.get(属性名)
